# 深度学习数据集
## 图像类
- [ImageNet](http://www.image-net.org/): 根据WordNet层次结构（目前只有名词）组织的图像数据库，其中层次结构的每个节点都由数百和数千个图像描绘。ImageNet是全球最大的开源图片库，截至到现在（2017.5）ImageNet共有一千四百多万张图片。其中包括超过20000个synset(s)，synset是近义词的合集，synsnet可以理解为ImageNet整理的标签。
- [CIFAR](http://www.cs.toronto.edu/~kriz/cifar.html): 由Alex Krizhevsky, Vinod Nair和 Geoffrey Hinton收集并整理，在Visual Dictionary的80万张图片中选择了6万张，并把它们分为CIFAR-10 和CIFAR-100。CIFAR-10数据集包含60000个32*32的彩色图像，共有10类。有50000个训练图像和10000个测试图像。数据集分为5个训练块和1个测试块，每个块有10000个图像。测试块包含从每类随机选择的1000个图像。训练块以随机的顺序包含这些图像，但一些训练块可能比其它类包含更多的图像。训练块每类包含5000个图像。CIFAR-100数据集包含100小类，每小类包含600个图像，其中有500个训练图像和100个测试图像。100类被分组为20个大类。 
- [MNIST](http://yann.lecun.com/exdb/mnist/): 深度学习领域中大名鼎鼎的数据集—MNIST,几乎所有的深度学习教程的入门实例都是手写数字识别，而它们用到的库就是MNIST。这就好比我们学习一门语言的时候显示”hello world”。 MNIST数据集共包含7万个样本，分别是手写体数字0~9，样本大小为28*28。
- [COCO](http://cocodataset.org/#home): 由微软赞助，其对于图像的标注信息不仅有类别、位置信息，还有对图像的语义文本描述，COCO数据集的开源使得近两三年来图像分割语义理解取得了巨大的进展，也几乎成为了图像语义理解算法性能评价的“标准”数据集。
- [CityScapes](https://www.cityscapes-dataset.com/dataset-overview/): 数据场景包括50个不同城市（主要在德国），春夏秋三个季节白天的场景，有大量的动态目标不同层次的场景和多样的背景。场景不包括下大雨的和下雪的，因为这种场景需要用特殊的技术处理。图像数据分为30类：除了有 5000帧细标注的（像素级别的），标注一张图时间控制在１.5h左右，精细标注的数据划分成如下图训练验证测试集，不是随机划分的，而是确保每个划分的数据集里面包含各种场景。最终有2975张用来训练，500张用来验证，1525张用来测试。此外，还有20000张弱标注的帧，只用来训练，标注一张图控制在７min内。 


## SLAM数据集
- [TUM RGB-D](https://vision.in.tum.de/data/datasets/rgbd-dataset/download): TUM RGB-D数据集由在不同的室内场景使用Microsoft Kinect传感器记录的39 个序列组成。包含了Testing and Debugging（测试），Handheld SLAM（手持SLAM），Robot SLAM（机器人SLAM），Structure vs. Texture（结构 vs 低纹理），Dynamic Objects（动态物体），3D Object Reconstruction（三维物体重建），Validation Files（验证集），Calibration Files（标定文件）几种针对不同任务的数据集，每个种类有包含多个数据，可以用于多种任务的性能测试。其groundtruth通过光学捕捉系统获得。其中的Dynamic Objects中包含了9个包含groundtrth的数据集，以及每个每种轨迹的验证集。该数据集涵括了四种相机运动姿态（xyz、rpy、halfsphere、static），以及两种动态程度（sitting、walking）。该动态数据集被广泛应用于动态SLAM系统的定位精度评估，如DynaSLAM、DsSLAM等都以该数据集为主要评测对象。值得一提的是，该网站还自带了在线评测工具，将自己的轨迹上传即可获得各项指标。
- [KITTI](http://www.cvlibs.net/datasets/kitti/raw_data.php): KITTI数据集由德国卡尔斯鲁厄理工学院和丰田美国技术研究院联合创办，是目前国际上最大的自动驾驶场景下的计算机视觉算法评测数据集。该数据集用于评测立体图像(stereo)，光流(optical flow)，视觉测距(visual odometry)，3D物体检测(object detection)和3D跟踪(tracking)等计算机视觉技术在车载环境下的性能。KITTI数据集的数据采集平台装配有2个灰度摄像机，2个彩色摄像机，一个Velodyne 64线3D激光雷达，4个光学镜头，以及1个GPS导航系统。其中visual odometry中包含的22个道路环境中采集的双目视频序列，可以用来评估SLAM系统在户外动态环境下的定位性能（以及运动物体跟踪性能）。目前，包括Dyna SALAMII、VDO-SLAM等著名的户外动态SLAM系统都是用了该数据集进行性能评估。此外，考虑到这些轨迹中有回环的部分，一些研究回环检测的人员制作了某些序列（00、02、05、06、07、08、09、13、15、16、18、19）中的回环真值，可以用来研究动态环境下回环检测的内容。
- [ReFusion](http://www.ipb.uni-bonn.de/data/rgbd-dynamic-dataset/): ReFusion是一个出色的、不采用深度学技术的、可以运行在动态环境中的三位实时重建系统。在该论文中，他们采集了自己的数据集，包括9种场景的24个视频序列，比TUM动态数据集的场景更加丰富，也更及复杂。他们用专业的地面激光雷达采集了环境静态部分的高分辨率点云，然后将点云对齐到我们的运动捕捉系统。之后RGB-D传感器的参考坐标系转换为运动捕捉系统的参考坐标系。目前，该数据集逐渐被一些三位重建的论文所采用。
- [Dynamic-Scenes](https://github.com/HaoshengChen/Dynamic-Scenes): 场景中的动态物体不仅会影响SLAM短期的定位精度（帧间运动估计），还会影响长期定位性能（回环检测）。陈等人提出了一种SLCD进行回环检测，并发布了用于户外动态环境下回环检测的数据集。他们在道路环境中用ZED相机制作了两段数据，包括CBD与Road Ring。其中CBD的轨迹为一个环形，回环只有一处。Road Ring的轨迹有多处回环，且回环处存在多出动态物体，很适合研究动态动态场景对场景识别的影响。但是该数据集并没有给相机的参数，且没有轨迹的groungtruth，目前并不能直接使用，可信度并不是很高。
